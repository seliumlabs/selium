//! Orchestrates processes and channels to demonstrate Selium's control plane.
//!
//! This example is intentionally compact but feature-rich:
//! - The orchestrator spawns child processes from the same module.
//! - It wires shared channels for config, work, and results.
//! - It streams config updates while work is in flight.
//! - It collects results and shuts down cleanly.

use std::time::Duration;

use anyhow::{Context, Result, anyhow};
use futures::{FutureExt, SinkExt, StreamExt};
use selium_userland::{
    abi::{AbiParam, AbiScalarType, AbiScalarValue, AbiSignature, GuestResourceId},
    encoding::FlatMsg,
    entrypoint,
    io::{Channel, SharedChannel},
    process::{Capability, ProcessBuilder, ProcessHandle},
    schema, time,
};
use tracing::{info, warn};

/// Flatbuffer bindings generated by the build script.
#[rustfmt::skip]
#[allow(warnings)]
pub mod fbs;

/// Default buffer size for the in-memory channels used in this demo.
const CHANNEL_CAPACITY: u32 = 64 * 1024;
/// Number of config updates to publish if not supplied.
const DEFAULT_UPDATE_COUNT: u32 = 3;
/// Delay between config updates, in milliseconds.
const DEFAULT_UPDATE_INTERVAL_MS: u32 = 250;
/// Root URI for per-process log streams.
const LOG_URI_ROOT: &str = "sel://example.org/orchestrator/logs/";

#[schema(
    path = "schemas/orchestrator.fbs",
    ty = "examples.orchestrator.ConfigUpdate",
    binding = "crate::fbs::examples::orchestrator::ConfigUpdate"
)]
/// Configuration payload broadcast by the config publisher.
struct ConfigUpdate {
    version: u32,
    multiplier: u32,
    note: String,
}

#[schema(
    path = "schemas/orchestrator.fbs",
    ty = "examples.orchestrator.WorkItem",
    binding = "crate::fbs::examples::orchestrator::WorkItem"
)]
/// Work payload pushed by the orchestrator.
struct WorkItem {
    id: u32,
    payload: String,
}

#[schema(
    path = "schemas/orchestrator.fbs",
    ty = "examples.orchestrator.WorkResult",
    binding = "crate::fbs::examples::orchestrator::WorkResult"
)]
/// Response emitted by the worker.
struct WorkResult {
    id: u32,
    worker: String,
    config_version: u32,
    output: String,
}

/// Current configuration snapshot applied by the worker.
#[derive(Debug, Clone)]
struct ConfigState {
    version: u32,
    multiplier: u32,
    note: String,
}

impl ConfigState {
    /// Apply an incoming update to the in-memory configuration state.
    fn apply(&mut self, update: ConfigUpdate) {
        self.version = update.version;
        self.multiplier = update.multiplier.max(1);
        self.note = update.note;
    }

    /// Build a result payload based on the current configuration.
    fn result_for(&self, worker: &str, item: &WorkItem) -> WorkResult {
        let output = format!("{} Ã— {} ({})", item.payload, self.multiplier, self.note);
        WorkResult::new(item.id, worker.to_string(), self.version, output)
    }
}

impl Default for ConfigState {
    fn default() -> Self {
        Self {
            version: 0,
            multiplier: 1,
            note: "boot".to_string(),
        }
    }
}

/// Entry point that spawns child processes, dispatches work, and aggregates results.
#[entrypoint]
async fn orchestrator(module_id: &str, worker_label: &str, task_count: u32) -> Result<()> {
    if module_id.is_empty() || worker_label.is_empty() || task_count == 0 {
        anyhow::bail!("invalid input parameters");
    }

    // Create channels for process comms
    let config_channel = Channel::create(CHANNEL_CAPACITY).await?;
    let config_shared = config_channel.share().await?;

    let task_channel = Channel::create(CHANNEL_CAPACITY).await?;
    let task_shared = task_channel.share().await?;

    let result_channel = Channel::create(CHANNEL_CAPACITY).await?;
    let result_shared = result_channel.share().await?;

    // Spawn the config publisher that keeps workers appraised of config changes
    let config_handle = spawn_config_publisher(
        module_id,
        config_shared,
        DEFAULT_UPDATE_COUNT,
        DEFAULT_UPDATE_INTERVAL_MS,
    )
    .await?;

    // Spawn workers to handle incoming tasks
    let worker_handle = spawn_worker(
        module_id,
        config_shared,
        task_shared,
        result_shared,
        worker_label,
        task_count,
    )
    .await?;

    // Send tasks to workers
    info!(tasks = task_count, "dispatching work");
    let mut task_writer = task_channel.publish().await?;
    for id in 0..task_count {
        let item = WorkItem::new(id, format!("payload-{id}"));
        task_writer.send(WorkItem::encode(&item)).await?;
    }
    task_writer.flush().await?;

    // Read results until we see all tasks or the channel closes.
    let mut result_reader = result_channel.subscribe(CHANNEL_CAPACITY).await?;
    let mut results = 0;
    while results < task_count {
        let frame = match result_reader.next().await.transpose()? {
            Some(frame) => frame,
            None => {
                warn!(
                    received = results,
                    expected = task_count,
                    "result channel ended early"
                );
                break;
            }
        };
        let result = WorkResult::decode(&frame.payload).map_err(|e| anyhow!(e))?;
        info!(
            task_id = result.id,
            worker = result.worker,
            config = result.config_version,
            output = result.output,
            "work completed"
        );
        results += 1;
    }

    // Shut down the child processes explicitly.
    worker_handle.stop().await.context("stop worker")?;
    config_handle
        .stop()
        .await
        .context("stop config publisher")?;

    Ok(())
}

/// Entry point that publishes rolling configuration updates.
#[entrypoint]
async fn config_publisher(
    config_channel: GuestResourceId,
    updates: u32,
    interval_ms: u32,
) -> Result<()> {
    assert!(updates > 0);

    let config_channel = attach_shared_channel(config_channel).await?;
    let mut writer = config_channel.publish().await?;

    for index in 0..updates {
        let version = index + 1;
        let multiplier = (index + 1) * 2;
        let note = format!("rollout {version}");
        let update = ConfigUpdate::new(version, multiplier, note);
        writer.send(ConfigUpdate::encode(&update)).await?;
        info!(version, multiplier, "published config update");

        if interval_ms > 0 && version < updates {
            time::sleep(Duration::from_millis(interval_ms as u64))
                .await
                .context("sleep between updates")?;
        }
    }

    writer.flush().await?;
    Ok(())
}

/// Entry point that consumes config + work and emits results.
#[entrypoint]
async fn worker(
    config_channel: GuestResourceId,
    task_channel: GuestResourceId,
    result_channel: GuestResourceId,
    worker_label: &str,
    max_tasks: u32,
) -> Result<()> {
    assert!(max_tasks > 0);
    assert!(!worker_label.is_empty());
    info!(worker = worker_label, "worker ready");

    let config_channel = attach_shared_channel(config_channel).await?;
    let task_channel = attach_shared_channel(task_channel).await?;
    let result_channel = attach_shared_channel(result_channel).await?;

    let mut config_reader = config_channel.subscribe(CHANNEL_CAPACITY).await?;
    let mut task_reader = task_channel.subscribe(CHANNEL_CAPACITY).await?;
    let mut result_writer = result_channel.publish().await?;

    let mut config = ConfigState::default();
    let mut processed = 0;
    let mut config_closed = false;

    while processed < max_tasks {
        if config_closed {
            let Some(frame) = task_reader.next().await.transpose()? else {
                break;
            };
            let item = WorkItem::decode(&frame.payload).map_err(|e| anyhow!(e))?;
            let result = config.result_for(worker_label, &item);
            result_writer.send(WorkResult::encode(&result)).await?;
            processed += 1;
            continue;
        }

        let next_config = config_reader.next().fuse();
        let next_task = task_reader.next().fuse();
        futures::pin_mut!(next_config, next_task);

        // Whichever arrives first wins: config updates are applied immediately.
        futures::select! {
            config_frame = next_config => {
                let Some(frame) = config_frame.transpose()? else {
                    config_closed = true;
                    continue;
                };
                let update = ConfigUpdate::decode(&frame.payload)
                    .map_err(|e| anyhow!(e))?;
                config.apply(update);
                info!(
                    worker = worker_label,
                    version = config.version,
                    note = %config.note,
                    "config applied"
                );
            }
            task_frame = next_task => {
                let Some(frame) = task_frame.transpose()? else {
                    break;
                };
                let item = WorkItem::decode(&frame.payload).map_err(|e| anyhow!(e))?;
                let result = config.result_for(worker_label, &item);
                result_writer.send(WorkResult::encode(&result)).await?;
                processed += 1;
            }
        }
    }

    result_writer.flush().await?;
    Ok(())
}

/// Build the log URI for a child process.
fn log_uri(process: &str) -> String {
    format!("{LOG_URI_ROOT}{process}")
}

/// Attach a shared channel handle from another process.
async fn attach_shared_channel(handle: GuestResourceId) -> Result<Channel> {
    let shared = unsafe { SharedChannel::from_raw(handle) };
    Channel::attach_shared(shared)
        .await
        .context("attach shared channel")
}

/// Spawn the config publisher and return its process handle.
async fn spawn_config_publisher(
    module_id: &str,
    config_channel: SharedChannel,
    updates: u32,
    interval_ms: u32,
) -> Result<ProcessHandle> {
    let signature = AbiSignature::new(
        vec![
            AbiParam::Scalar(AbiScalarType::U64),
            AbiParam::Scalar(AbiScalarType::U32),
            AbiParam::Scalar(AbiScalarType::U32),
        ],
        Vec::new(),
    );

    ProcessBuilder::new(module_id, "config_publisher")
        .capability(Capability::ChannelLifecycle)
        .capability(Capability::ChannelWriter)
        .capability(Capability::TimeRead)
        .signature(signature)
        .log_uri(log_uri("config_publisher"))
        .arg_resource(config_channel.raw())
        .arg_scalar(AbiScalarValue::U32(updates))
        .arg_scalar(AbiScalarValue::U32(interval_ms))
        .start()
        .await
        .context("start config publisher")
}

/// Spawn the worker and return its process handle.
async fn spawn_worker(
    module_id: &str,
    config_channel: SharedChannel,
    task_channel: SharedChannel,
    result_channel: SharedChannel,
    worker_label: &str,
    max_tasks: u32,
) -> Result<ProcessHandle> {
    let signature = AbiSignature::new(
        vec![
            AbiParam::Scalar(AbiScalarType::U64),
            AbiParam::Scalar(AbiScalarType::U64),
            AbiParam::Scalar(AbiScalarType::U64),
            AbiParam::Buffer,
            AbiParam::Scalar(AbiScalarType::U32),
        ],
        Vec::new(),
    );

    ProcessBuilder::new(module_id, "worker")
        .capability(Capability::ChannelLifecycle)
        .capability(Capability::ChannelReader)
        .capability(Capability::ChannelWriter)
        .signature(signature)
        .log_uri(log_uri("worker"))
        .arg_resource(config_channel.raw())
        .arg_resource(task_channel.raw())
        .arg_resource(result_channel.raw())
        .arg_utf8(worker_label)
        .arg_scalar(AbiScalarValue::U32(max_tasks))
        .start()
        .await
        .context("start worker")
}
